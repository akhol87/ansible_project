<repo-to-text>
Directory: ansible

Directory Structure:
[ansible@prdx-ansible101 /ansible]$ tree
.
â”œâ”€â”€ apache_vhosts.yml
â”œâ”€â”€ copy-yum-repos.yml
â”œâ”€â”€ dns_clients.yml
â”œâ”€â”€ dns_dynamic.yml
â”œâ”€â”€ haproxy.yml
â”œâ”€â”€ ntp_clients.yml
â”œâ”€â”€ ntp_master.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ repo-to-text_2025-12-04-21-55-51-UTC.txt
â””â”€â”€ roles
    â”œâ”€â”€ apache_vhosts
    â”‚   â”œâ”€â”€ defaults
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â”œâ”€â”€ handlers
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â”œâ”€â”€ tasks
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â””â”€â”€ templates
    â”‚       â”œâ”€â”€ index.html.j2
    â”‚       â””â”€â”€ vhost.conf.j2
    â”œâ”€â”€ dns_clients
    â”‚   â”œâ”€â”€ tasks
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â””â”€â”€ templates
    â”‚       â””â”€â”€ resolv.conf.j2
    â”œâ”€â”€ dns_dynamic
    â”‚   â”œâ”€â”€ defaults
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â”œâ”€â”€ handlers
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â”œâ”€â”€ tasks
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â””â”€â”€ templates
    â”‚       â”œâ”€â”€ db.forward.j2
    â”‚       â”œâ”€â”€ db.reverse.j2
    â”‚       â”œâ”€â”€ named.conf.j2
    â”‚       â””â”€â”€ named.conf.j2.bak
    â”œâ”€â”€ haproxy_lb
    â”‚   â”œâ”€â”€ handlers
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â”œâ”€â”€ tasks
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â””â”€â”€ templates
    â”‚       â””â”€â”€ haproxy.cfg.j2
    â”œâ”€â”€ ntp_clients
    â”‚   â”œâ”€â”€ defaults
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â”œâ”€â”€ handlers
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â”œâ”€â”€ tasks
    â”‚   â”‚   â””â”€â”€ main.yml
    â”‚   â””â”€â”€ templates
    â”‚       â””â”€â”€ chrony.conf.j2
    â””â”€â”€ ntp_master
        â”œâ”€â”€ defaults
        â”‚   â””â”€â”€ main.yml
        â”œâ”€â”€ handlers
        â”‚   â””â”€â”€ main.yml
        â”œâ”€â”€ tasks
        â”‚   â””â”€â”€ main.yml
        â””â”€â”€ templates
            â””â”€â”€ ntp-master.conf.j2

28 directories, 34 files

</directory_structure>

<content full_path="dns_dynamic.yml">
---
- name: Dynamic DNS rebuild using inventory
  hosts: dns_primary
  become: yes
  roles:
    - dns_dynamic

</content>

<content full_path="dns_clients.yml">
---
- name: Install bind-utils on all client servers
  hosts: all:!dns_primary        # all servers except nds_primary
  become: yes
  roles:
    - dns_clients

</content>

<content full_path="ntp_master.yml">
---
- name: Configure NTP master server
  hosts: ntp_master
  become: yes
  roles:
    - ntp_master

</content>

<content full_path="ntp_clients.yml">
---
- name: Configure NTP clients
  hosts: ntp_clients
  become: yes
  roles:
    - ntp_clients

</content>

<content full_path="README.md">
My project Documentation

</content>

<content full_path="apache_vhosts.yml">
---
- name: Configure Apache Virtual Hosts on Load Balancer
  hosts: load_balancer
  become: yes
  roles:
    - apache_vhosts
</content>

<content full_path="haproxy.yml">
---
- name: Configure HAProxy Load Balancer
  hosts: load_balancer
  become: yes
  roles:
    - haproxy_lb
</content>

<content full_path="copy-yum-repos.yml">
---
- name: Ensure rsync is installed on prdx-ntp101
  hosts: prdx-ntp101
  become: yes
  gather_facts: no

  tasks:
    - name: Install rsync package
      dnf:
        name: rsync
        state: present


- name: Copy yum.repos.d from prdx-ntp101 to all servers
  hosts: all
  become: yes
  gather_facts: no

  tasks:
    - name: Copy yum.repos.d directory using rsync from prdx-ntp101
      synchronize:
        src: /etc/yum.repos.d/
        dest: /etc/yum.repos.d/
        delete: no
        recursive: yes
        mode: pull
      delegate_to: prdx-ntp101
      when: inventory_hostname not in [
              'prdx-ansible101',
              'prdx-nsprimary101',
              'prdx-db101'
            ]

</content>

<content full_path="roles/dns_clients/tasks/main.yml">
---
- name: Install bind-utils on client servers
  yum:
    name: bind-utils
    state: present
    update_cache: yes

- name: Disable SELinux
  selinux:
    state: disabled    

- name: Deploy resolv.conf for clients
  template:
    src: resolv.conf.j2
    dest: /etc/resolv.conf
  when: inventory_hostname != "prdx-nsprimary101"


</content>

<content full_path="roles/dns_clients/templates/resolv.conf.j2">
search ziyotek.local
nameserver 10.0.0.53
</content>

<content full_path="roles/dns_dynamic/templates/named.conf.j2">
options {
    directory "/var/named";
    listen-on port 53 { any; };           # listen on all IPv4 interfaces
    listen-on-v6 { none; };               # disable IPv6 to avoid recursion issues
    recursion yes;                        # enable recursion

allow-recursion { 127.0.0.1; 10.0.0.0/24; };
allow-query-cache { 127.0.0.1; 10.0.0.0/24; };
allow-query { 127.0.0.1; 10.0.0.0/24; };


    forwarders {
        8.8.8.8;                           # Google DNS
        1.1.1.1;                           # Cloudflare DNS
    };
    forward only;                          # only use forwarders for external domains
};

logging {
    channel default_debug {
        file "data/named.run";
        severity dynamic;
    };
};

zone "ziyotek.local" IN {
    type master;
    file "/var/named/db.forward";
    allow-transfer { any; };
};

zone "0.0.10.in-addr.arpa" IN {
    type master;
    file "/var/named/db.reverse";
    allow-transfer { any; };
};

</content>

<content full_path="roles/dns_dynamic/templates/db.forward.j2">
$TTL 86400
@   IN  SOA {{ dns_primary }}. admin.{{ dns_domain }}. (
    {{ lookup('pipe','date +%Y%m%d%H') }} ; Serial
    3600 ; Refresh
    1800 ; Retry
    604800 ; Expire
    86400 ) ; Negative Cache TTL
;
@       IN  NS  {{ dns_primary }}.

{% for host in groups['all'] %}
{{ hostvars[host].inventory_hostname }}.{{ dns_domain }}. IN A {{ hostvars[host].ansible_host }}
{% endfor %}

</content>

<content full_path="roles/dns_dynamic/templates/db.reverse.j2">
$TTL 86400
@   IN  SOA {{ dns_primary }}. admin.{{ dns_domain }}. (
    {{ lookup('pipe','date +%Y%m%d%H') }}
    3600
    1800
    604800
    86400 )
;
@       IN  NS  {{ dns_primary }}.

{% for host in groups['all'] %}
{{ hostvars[host].ansible_host.split('.')[-1] }} IN PTR {{ hostvars[host].inventory_hostname }}.
{% endfor %}

</content>

<content full_path="roles/dns_dynamic/templates/named.conf.j2.bak">
options {
    directory "/var/named";
    listen-on port 53 { any; };
    listen-on-v6 { none; };
    recursion yes;
    allow-query-cache { 10.0.0.0/24; };
    allow-recursion { any; };
    allow-query { any; };

    forwarders {
        8.8.8.8;
        1.1.1.1;
    };
    forward only;
};

zone "ziyotek.local" IN {
    type master;
    file "/var/named/db.forward";
    allow-transfer { any; };
};

zone "0.0.10.in-addr.arpa" IN {
    type master;
    file "/var/named/db.reverse";
    allow-transfer { any; };
};
</content>

<content full_path="roles/dns_dynamic/tasks/main.yml">
---
- name: Install BIND
  yum:
    name: bind
    state: present

- name: Ensure named is enabled
  service:
    name: named
    enabled: yes
    state: started

- name: Disable SELinux
  selinux:
    state: disabled

- name: Allow DNS in firewall
  firewalld:
    service: dns
    state: enabled
    permanent: yes
    immediate: yes

- name: Generate named.conf from template
  template:
    src: named.conf.j2
    dest: /etc/named.conf
    owner: root
    group: named
    mode: '0640'
    backup: yes
  notify:
    - Check named syntax
    - Check forward zone syntax
    - Check reverse zone syntax
    - Restart DNS

- name: Generate forward zone db
  template:
    src: db.forward.j2
    dest: /var/named/db.forward
    owner: named
    group: named
    mode: '0640'
  notify:
    - Check forward zone syntax
    - Restart DNS

- name: Generate reverse zone db
  template:
    src: db.reverse.j2
    dest: /var/named/db.reverse
    owner: named
    group: named
    mode: '0640'
  notify:
    - Check reverse zone syntax
    - Restart DNS

</content>

<content full_path="roles/dns_dynamic/handlers/main.yml">
---
- name: Check named syntax
  command: named-checkconf
  listen: "Check named syntax"

- name: Check forward zone syntax
  command: named-checkzone {{ dns_domain }} /var/named/db.forward
  listen: "Check forward zone syntax"

- name: Check reverse zone syntax
  command: named-checkzone 0.0.10.in-addr.arpa /var/named/db.reverse
  listen: "Check reverse zone syntax"

- name: Restart DNS
  service:
    name: named
    state: restarted

</content>

<content full_path="roles/dns_dynamic/defaults/main.yml">
---
dns_domain: "ziyotek.local"
dns_primary: "prdx-nsprimary101"

</content>

<content full_path="roles/ntp_master/defaults/main.yml">
ntp_pool:
  - server time.google.com iburst
  - server time.cloudflare.com iburst

ntp_allow_network: 10.0.0.0/24

</content>

<content full_path="roles/ntp_master/handlers/main.yml">
- name: restart firewalld
  service: 
    name: firewalld
    state: restarted

- name: restart chronyd
  systemd:
    name: chronyd
    state: restarted    
</content>

<content full_path="roles/ntp_master/tasks/main.yml">
- name: Install chrony
  yum:
    name: chrony
    state: present

- name: Deploy NTP master configuration
  template:
    src: ntp-master.conf.j2
    dest: /etc/chrony.conf
    owner: root
    group: root
    mode: '0644'
  notify: restart chronyd

- name: Enable NTP service in firewalld
  firewalld:
    service: ntp
    permanent: yes
    state: enabled
    immediate: yes
  notify: restart firewalld

- name: Enable and start chronyd
  systemd:
    name: chronyd
    enabled: yes
    state: started

</content>

<content full_path="roles/ntp_master/templates/ntp-master.conf.j2">
# NTP Master
{% for server in ntp_pool %}
server {{ server }}
{% endfor %}

allow {{ ntp_allow_network }}
local stratum 10

driftfile /var/lib/chrony/drift
makestep 1.0 3
rtcsync
logdir /var/log/chrony

</content>

<content full_path="roles/ntp_clients/defaults/main.yml">
ntp_master_ip: 10.0.0.51
ntp_master_hostname: prdx-ntp101

</content>

<content full_path="roles/ntp_clients/handlers/main.yml">
- name: restart chronyd
  systemd:
    name: chronyd
    state: restarted

</content>

<content full_path="roles/ntp_clients/tasks/main.yml">
- name: Make yum cache
  yum:
    update_cache: yes

- name: Install chrony
  yum:
    name: chrony
    state: present

- name: Deploy NTP client configuration
  template:
    src: chrony.conf.j2
    dest: /etc/chrony.conf
    mode: '0644'
  notify: restart chronyd

- name: Enable and start chronyd
  systemd:
    name: chronyd
    enabled: yes
    state: started

- name: Force initial time step if offset is large
  command: chronyc -a makestep
  register: makestep
  changed_when: "'Frequency' in makestep.stdout"


</content>

<content full_path="roles/ntp_clients/templates/chrony.conf.j2">
# NTP Client â€“ syncs only from internal master
server {{ ntp_master_ip }} iburst

driftfile /var/lib/chrony/drift
makestep 1.0 3
rtcsync
logdir /var/log/chrony

</content>

<content full_path="roles/apache_vhosts/defaults/main.yml">
---
bambi_image_url: "https://wallscloud.net/img/resize/1600/1200/MM/2016-09-25-disney-bambi-movie-kJJ.jpg"
</content>

<content full_path="roles/apache_vhosts/handlers/main.yml">
---
- name: restart httpd
  systemd:
    name: httpd
    state: restarted

- name: restart firewalld
  systemd:
    name: firewalld
    state: restarted
</content>

<content full_path="roles/apache_vhosts/tasks/main.yml">
---
- name: Install Apache (httpd)
  yum:
    name: httpd
    state: present

- name: Disable SELinux
  selinux:
    state: disabled

- name: Create directories for virtual hosts
  file:
    path: "/var/www/vhost{{ item }}"
    state: directory
    owner: apache
    group: apache
    mode: '0755'
  loop:
    - 1
    - 2
    - 3

- name: Download Bambi image for each virtual host
  get_url:
    url: "{{ bambi_image_url }}"
    dest: "/var/www/vhost{{ item }}/bambi.jpg"
    owner: apache
    group: apache
    mode: '0644'
  loop:
    - 1
    - 2
    - 3

- name: Deploy index.html for Virtual Host 1
  template:
    src: index.html.j2
    dest: /var/www/vhost1/index.html
    owner: apache
    group: apache
    mode: '0644'
  vars:
    page_number: 1

- name: Deploy index.html for Virtual Host 2
  template:
    src: index.html.j2
    dest: /var/www/vhost2/index.html
    owner: apache
    group: apache
    mode: '0644'
  vars:
    page_number: 2

- name: Deploy index.html for Virtual Host 3
  template:
    src: index.html.j2
    dest: /var/www/vhost3/index.html
    owner: apache
    group: apache
    mode: '0644'
  vars:
    page_number: 3

- name: Configure Virtual Host 1 (Port 7000)
  template:
    src: vhost.conf.j2
    dest: /etc/httpd/conf.d/vhost1.conf
    owner: root
    group: root
    mode: '0644'
  vars:
    port: 7000
    doc_root: /var/www/vhost1
  notify: restart httpd

- name: Configure Virtual Host 2 (Port 8000)
  template:
    src: vhost.conf.j2
    dest: /etc/httpd/conf.d/vhost2.conf
    owner: root
    group: root
    mode: '0644'
  vars:
    port: 8000
    doc_root: /var/www/vhost2
  notify: restart httpd

- name: Configure Virtual Host 3 (Port 9000)
  template:
    src: vhost.conf.j2
    dest: /etc/httpd/conf.d/vhost3.conf
    owner: root
    group: root
    mode: '0644'
  vars:
    port: 9000
    doc_root: /var/www/vhost3
  notify: restart httpd

- name: Allow ports 7000, 8000, 9000 in firewalld
  firewalld:
    port: "{{ item }}/tcp"
    permanent: yes
    state: enabled
    immediate: yes
  loop:
    - 7000
    - 8000
    - 9000
  notify: restart firewalld

- name: Enable and start httpd
  systemd:
    name: httpd
    enabled: yes
    state: started
</content>

<content full_path="roles/apache_vhosts/templates/vhost.conf.j2">
Listen {{ port }}

<VirtualHost *:{{ port }}>
    DocumentRoot {{ doc_root }}
    
    <Directory {{ doc_root }}>
        Options Indexes FollowSymLinks
        AllowOverride None
        Require all granted
    </Directory>
    
    ErrorLog /var/log/httpd/vhost_{{ port }}_error.log
    CustomLog /var/log/httpd/vhost_{{ port }}_access.log combined
</VirtualHost>
</content>

<content full_path="roles/apache_vhosts/templates/index.html.j2">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Page {{ page_number }} - Load Balancer Demo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Arial', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            padding: 40px;
            max-width: 900px;
            text-align: center;
        }
        
        h1 {
            color: #333;
            font-size: 3em;
            margin-bottom: 20px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1);
        }
        
        .page-number {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px 30px;
            border-radius: 50px;
            font-size: 2em;
            font-weight: bold;
            display: inline-block;
            margin-bottom: 30px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .server-info {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
            border-left: 5px solid #667eea;
        }
        
        .server-info p {
            color: #555;
            font-size: 1.1em;
            margin: 10px 0;
        }
        
        .server-info strong {
            color: #333;
        }
        
        .image-container {
            margin-top: 30px;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }
        
        img {
            width: 100%;
            height: auto;
            display: block;
        }
        
        .footer {
            margin-top: 30px;
            color: #666;
            font-size: 0.9em;
        }
        
        .refresh-hint {
            background: #fff3cd;
            border: 1px solid #ffc107;
            color: #856404;
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¯ Load Balancer Demo</h1>
        
        <div class="page-number">
            Page {{ page_number }}
        </div>
        
        <div class="server-info">
            <p><strong>Server:</strong> {{ ansible_hostname }}</p>
            <p><strong>IP Address:</strong> {{ ansible_default_ipv4.address }}</p>
            <p><strong>Backend Port:</strong> {{ 7000 if page_number == 1 else (8000 if page_number == 2 else 9000) }}</p>
        </div>
        
        <div class="refresh-hint">
            ðŸ”„ Refresh this page multiple times to see the load balancer in action!
        </div>
        
        <div class="image-container">
            <img src="bambi.jpg" alt="Bambi - Disney">
        </div>
        
        <div class="footer">
            <p>Powered by Apache & HAProxy | Ziyotek Infrastructure</p>
        </div>
    </div>
</body>
</html>
</content>

<content full_path="roles/haproxy_lb/handlers/main.yml">
---
- name: restart haproxy
  systemd:
    name: haproxy
    state: restarted

- name: restart firewalld
  systemd:
    name: firewalld
    state: restarted
</content>

<content full_path="roles/haproxy_lb/tasks/main.yml">
---
- name: Install HAProxy
  yum:
    name: haproxy
    state: present

- name: Deploy HAProxy configuration
  template:
    src: haproxy.cfg.j2
    dest: /etc/haproxy/haproxy.cfg
    owner: root
    group: root
    mode: '0644'
    backup: yes
  notify: restart haproxy

- name: Allow HTTP (port 80) in firewalld
  firewalld:
    service: http
    permanent: yes
    state: enabled
    immediate: yes
  notify: restart firewalld

- name: Allow HAProxy stats page (port 8404) in firewalld
  firewalld:
    port: 8404/tcp
    permanent: yes
    state: enabled
    immediate: yes
  notify: restart firewalld

- name: Enable and start HAProxy
  systemd:
    name: haproxy
    enabled: yes
    state: started
</content>

<content full_path="roles/haproxy_lb/templates/haproxy.cfg.j2">
#---------------------------------------------------------------------
# Global settings
#---------------------------------------------------------------------
global
    log         127.0.0.1 local2
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon
    stats socket /var/lib/haproxy/stats

#---------------------------------------------------------------------
# Default settings
#---------------------------------------------------------------------
defaults
    mode                    http
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 3000

#---------------------------------------------------------------------
# HAProxy Statistics Page
#---------------------------------------------------------------------
listen stats
    bind *:8404
    stats enable
    stats uri /
    stats refresh 5s
    stats show-legends
    stats show-node

#---------------------------------------------------------------------
# Frontend - Accepts incoming HTTP requests
#---------------------------------------------------------------------
frontend http_front
    bind *:80
    default_backend apache_backend
    
    # Add custom header to show which backend server responded
    http-response set-header X-Backend-Server %s

#---------------------------------------------------------------------
# Backend - Apache Virtual Hosts (Round Robin Load Balancing)
#---------------------------------------------------------------------
backend apache_backend
    balance roundrobin
    option httpchk GET /
    
    # Backend servers (all on localhost with different ports)
    server vhost1 127.0.0.1:7000 check
    server vhost2 127.0.0.1:8000 check
    server vhost3 127.0.0.1:9000 check

    

</content>

<content full_path=".vscode/settings.json">
{
    "ansible.python.interpreterPath": "/usr/bin/python"
}
</content>

</repo-to-text>
